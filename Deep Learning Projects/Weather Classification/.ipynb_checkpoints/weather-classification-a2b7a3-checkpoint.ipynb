{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Motivation: </h1>\n",
    "<h3> Student for <i>IIT - Delhi</i> proposed using Computer Vision to predict the AQI (Air Quality Index). They this ideology to be easily accessable, hence proposed creating an Android App using TF Lite. They called this project as <span color='red'>Celestini Project</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('sBTqLHA95rs', width=1700, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import time\n",
    "import os\n",
    "# from collections import Counter\n",
    "# import copy\n",
    "import itertools\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torchvision\n",
    "# from torchvision.datasets import ImageFolder\n",
    "from torchvision import models, transforms\n",
    "# from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# from torch.optim import lr_scheduler\n",
    "# from torch.autograd import Variable\n",
    "import torch\n",
    "import gc\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Setting Manual Seed for Recreation of results\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# External Packages\n",
    "# pip -q install --upgrade pip\n",
    "# pip uninstall -y pillow\n",
    "# pip -q install pillow-simd\n",
    "# pip -q install torchsummary torch-lr-finder\n",
    "\n",
    "# from torchsummary import summary\n",
    "# from torch_lr_finder import LRFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetImagesFromFolder(PATH,Class_Folder,ext):\n",
    "    \"\"\"\n",
    "    This module can be used to import image data. It also takes care of resizing the images to 240x240 Pixels\n",
    "    \"\"\"\n",
    "    images = [Image.open(file).convert('RGB').resize((240,240),resample=Image.LANCZOS) for e in ext for file in glob.glob(PATH+Class_Folder+'/*.' + e)] \n",
    "    print(f\"Found {len(images)} in folder {Class_Folder}\")\n",
    "    np.random.shuffle(images)\n",
    "    return images,np.array([Class_Folder for i in range(len(images))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/kaggle/input/multiclass-weather-dataset/Multi-class Weather Dataset/'\n",
    "FOLDERS = os.listdir(DATA_PATH)\n",
    "ext = ['jpg','jpeg']\n",
    "le = LabelEncoder().fit(FOLDERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "ALL_IMAGES,ALL_LABELS = [],[]\n",
    "images_population ={}\n",
    "\n",
    "for Class_Folder in FOLDERS:\n",
    "    IMAGES,LABELS = GetImagesFromFolder(DATA_PATH,Class_Folder,ext)\n",
    "    images_population[Class_Folder] = LABELS.shape[0]\n",
    "    ALL_IMAGES.extend(IMAGES)\n",
    "    ALL_LABELS.extend(LABELS)\n",
    "    \n",
    "end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Distribution of Data:\n",
    "* This is import to know if we have Imbalanced Dataset.\n",
    "* Luckily we have a consistent dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({'Name':[i for i in images_population.keys()],'#Images':[i for i in images_population.values()]})\n",
    "\n",
    "colors = ['gold', 'mediumturquoise', 'darkorange', 'lightgreen']\n",
    "fig = px.pie(df,values='#Images',names='Name', hole=.3, width=600, height=600,opacity=.80)\n",
    "fig.update_traces(hoverinfo='label+percent',textfont_size=20, marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n",
    "fig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide', title={'text': 'Population of Various Classes','y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Dataset to differernt splits for Training, Tesing & Validation:-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "TRAIN_IMAGES, X_val_test, TRAIN_LABELS, y_val_test = train_test_split(ALL_IMAGES, ALL_LABELS, test_size=0.20, random_state=42,stratify=ALL_LABELS)\n",
    "VAL_IMAGES, TEST_IMAGES, VAL_LABELS, TEST_LABELS =  train_test_split(X_val_test, y_val_test, test_size=0.50, random_state=42,stratify=y_val_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Custom Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherDataset(Dataset):\n",
    "    def __init__(self, ImageData, Target, transform=None):\n",
    "        self.ImageData = ImageData\n",
    "        self.Target = torch.LongTensor(le.transform(Target))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.ImageData[index]\n",
    "        y = self.Target[index]\n",
    "        if self.transform:\n",
    "            x = Image.fromarray(np.uint8(np.array(self.ImageData[index]))) # Memory Efficient way\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.ImageData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This is a utility function to find out MEAN & STD for Normalizing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://youtu.be/y6IEcEBRZks\n",
    "def get_mean_std(loader):\n",
    "    # VAR[X] = E[X**2] - E[X]**2\n",
    "    channels_sum, channels_squared_sum, num_batches = 0,0,0\n",
    "    \n",
    "    for data,_ in loader:\n",
    "        channels_sum +=torch.mean(data,dim=[0,2,3])\n",
    "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
    "        num_batches += 1\n",
    "    \n",
    "    mean = channels_sum/num_batches\n",
    "    std = (channels_squared_sum/num_batches - mean**2)**0.5\n",
    "    return mean,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "transform = transforms.Compose([transforms.Resize((230,230)),transforms.ToTensor()])\n",
    "dataset = WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=4)\n",
    "mean,std = get_mean_std(loader)\n",
    "print(f\"Data loader has:\\n*\\tmean= {mean.tolist()}\\n*\\tstd= {std.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader to Mini Batches:\n",
    "This includes:-\n",
    "* Image Augementations\n",
    "* Mini Batch creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {'train':transforms.Compose([transforms.ColorJitter(),\n",
    "                                         transforms.RandomRotation(30),\n",
    "                                         transforms.Resize((240,240)),\n",
    "                                         transforms.RandomResizedCrop(230),\n",
    "                                         transforms.RandomHorizontalFlip(),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize(mean=mean,std=std),#transforms.RandomErasing()\n",
    "                                        ]),\n",
    "             'val':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()]),\n",
    "             \n",
    "             'test':transforms.Compose([transforms.Resize((230,230)),\n",
    "                                      transforms.ToTensor()])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "batch_size = {'train':25, 'val':50,'test':50}\n",
    "\n",
    "dataset_classes = ['Cloudy','Rain','Shine','Sunrise']\n",
    "\n",
    "\n",
    "image_datasets = {'train': WeatherDataset(TRAIN_IMAGES, TRAIN_LABELS, transform=transform['train']),\n",
    "                  'val':   WeatherDataset(VAL_IMAGES, VAL_LABELS, transform=transform['val']),\n",
    "                  'test':  WeatherDataset(TEST_IMAGES, TEST_LABELS, transform=transform['test'])\n",
    "}\n",
    "\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val','test']}\n",
    "\n",
    "dataloaders = {indx: torch.utils.data.DataLoader(image_datasets[indx], batch_size=batch_size[indx], num_workers=4, pin_memory=True, shuffle=True)\n",
    "              for indx in batch_size.keys()}\n",
    "\n",
    "print(\"Size for Dataset:\\n\\t* Train: %d\\n\\t* Valid: %d\\n\\t* Test: %d\"%(dataset_sizes['train'],dataset_sizes['val'],dataset_sizes['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Training & Validation Data:\n",
    "Please note, we are not visualizing Testing data, as it will be used for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display the image\n",
    "def imshow(img):\n",
    "    # Convert from tensor image\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of training images\n",
    "dataiter = iter(dataloaders['train'])\n",
    "images, labels = dataiter.next()\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "labels = le.inverse_transform([i.item() for i in labels])\n",
    "\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of validation images\n",
    "dataiter = iter(dataloaders['val'])\n",
    "images, labels = dataiter.next()\n",
    "# Convert images to numpy for display\n",
    "images = images.numpy()\n",
    "\n",
    "# Plot the images in the batch\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "\n",
    "# Display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(dataset_classes[labels[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions for Model Training & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, model_checkpoint=0, early_stop = 10, num_epochs=5):\n",
    "    start_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # number of epochs to train the model\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    early_stop_cnt = 0\n",
    "    last_epoch_loss = np.Inf\n",
    "    globaliter = 0\n",
    "\n",
    "    final_loss = np.Inf\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        globaliter+=1\n",
    "        # keep track of training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        train_corrects = 0\n",
    "\n",
    "        for data, target in dataloaders['train']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # perform a single optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # update training loss\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            train_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        train_loss = train_loss/len(dataloaders['train'].dataset)\n",
    "        train_acc = (train_corrects.double()*100)/len(dataloaders['train'].dataset)\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        val_corrects = 0\n",
    "        for data, target in dataloaders['val']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss\n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            val_corrects += torch.sum(preds == target.data)\n",
    "\n",
    "        # calculate average losses\n",
    "        valid_loss = valid_loss/len(dataloaders['val'].dataset)\n",
    "        valid_acc = (val_corrects.double()*100)/len(dataloaders['val'].dataset)\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss:  {:.6f} \\tValidation Loss:  {:.6f}'.format(epoch, train_loss, valid_loss))\n",
    "        print('\\t\\tTraining Acc:  {:.3f} \\t\\tValidation Acc:  {:.3f}'.format(train_acc, valid_acc))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('\\t\\tValidation loss decreased ({:.6f} --> {:.6f}).'.format(valid_loss_min,valid_loss))\n",
    "            if model_checkpoint != 0:\n",
    "                torch.save(model.state_dict(), '/kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "                print('Model Saved: /kaggle/working/model.pt'.format(train_acc, valid_acc))\n",
    "            valid_loss_min = valid_loss\n",
    "        elif valid_loss == np.nan:\n",
    "            print(\"Model Loss: NAN\")\n",
    "\n",
    "        if (last_epoch_loss < valid_loss) and last_epoch_loss != np.Inf:\n",
    "            early_stop_cnt +=1\n",
    "            if early_stop_cnt == early_stop:\n",
    "                print('-'*50+\"\\nEarly Stopping Hit\\n\"+'-'*50)\n",
    "                break\n",
    "            else:\n",
    "                print('-'*50+f\"\\n\\t\\tEarly Stopping Step: {early_stop_cnt}/{early_stop}\\n\"+'-'*50)\n",
    "        else:\n",
    "            early_stop_cnt = 0\n",
    "            last_epoch_loss = valid_loss\n",
    "\n",
    "    print(f\"Training Completed with best model having loss of {round(valid_loss_min,6)}\")\n",
    "    del data,target\n",
    "    gc.collect()\n",
    "    end_time = datetime.datetime.now().replace(microsecond=0)\n",
    "    print(f'Time Taken: {end_time-start_time}')\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    size = len(classes)*2\n",
    "    plt.figure(figsize = (size,size))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title,fontsize=20)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label',fontsize=16)\n",
    "    plt.xlabel('Predicted label',fontsize=16)\n",
    "\n",
    "    \n",
    "def model_verification(loader,batch_size,model,n_classes=5):\n",
    "    classes = list(le.inverse_transform([i for i in range(n_classes)]))\n",
    "    prediction_list,label_list = [],[]\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            predicted = outputs.argmax(dim=1).detach()\n",
    "            prediction_list.extend(predicted.tolist())\n",
    "            label_list.extend(labels.tolist())\n",
    "            \n",
    "    cm = confusion_matrix(prediction_list,label_list)\n",
    "    plot_confusion_matrix(cm, classes)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize = (num_images,num_images))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'Predicted: {dataset_classes[preds[j]]} | Actual: {dataset_classes[labels[j]]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "    if device.type == 'cuda':\n",
    "        inputs = inputs.cpu()\n",
    "        labels = labels.cpu()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training:\n",
    "We will be using DenseNet-161\n",
    "<center>\n",
    "    \n",
    "![DenseNet-161](https://mohuaxiao.github.io/2018/06/09/tensorflow/img/2018-6-9/densenet_Archi.JPG)\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "epochs = 25\n",
    "\n",
    "n_classes = len(dataset_classes)\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "# Using Model as Feature Extractor\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "model_ft.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "model_ft = model_ft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "decay = 0.01\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=lr, momentum = momentum, weight_decay = decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training of Model:')\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft,model_checkpoint=0,num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets visually check for the performance of our Model:\n",
    "1. Using Actual Vs Predicted\n",
    "2. Using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft, num_images=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verification(dataloaders['val'],batch_size['val'],model_ft,n_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, lets see the performance on Testing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_verification(dataloaders['test'],batch_size['test'],model_ft,n_classes=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
